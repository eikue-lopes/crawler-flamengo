{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faço as importações necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCu-z1zF497R"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKYwqDVy9AOb"
   },
   "source": [
    "Acesso o endpoint de notícias do site do Flamengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dWNiDg85BZe"
   },
   "outputs": [],
   "source": [
    "host = \"https://www.flamengorj.com.br\"\n",
    "MAX_BANNERS_PAGES = 10\n",
    "\n",
    "responses = []\n",
    "for i in range(1,MAX_BANNERS_PAGES+1):\n",
    "    url = host + \"/noticias\"\n",
    "    if i > 1:\n",
    "        url = url + f'/{i}'\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        responses.append(r)\n",
    "    elif r.status_code == 404:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHk-SwHb9GKP"
   },
   "source": [
    "Pego o conteúdo html recebido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wrXk_7f9Q8d"
   },
   "outputs": [],
   "source": [
    "htmls = [] \n",
    "for r in responses:\n",
    "    htmls.append(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkISeWZm9UjO"
   },
   "source": [
    "Pego os banners de notícias dentro dos htmls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0avBEfD95eF4",
    "outputId": "f6652e77-de03-450a-fb6e-62b84373fc9f"
   },
   "outputs": [],
   "source": [
    "banners = []\n",
    "for html in htmls:\n",
    "    bs = BeautifulSoup(html,features='html.parser')\n",
    "    banners_page = bs.find_all(\"div\",class_=\"post-grid__item col-12 col-md-6\")\n",
    "    for bpage in banners_page:\n",
    "        banners.append(bpage)\n",
    "\n",
    "qtd_noticias = len(banners)\n",
    "print(\"Quantidade de notícias capturadas:\",qtd_noticias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSKnB3Cy9lkk"
   },
   "source": [
    "Pego os links para cada notícia capturada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5TVswla9pGH"
   },
   "outputs": [],
   "source": [
    "links = []\n",
    "for bn in banners:\n",
    "  links.append(bn.find(\"a\")['href'])\n",
    "\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WtphHmi-yPT"
   },
   "source": [
    "Trato cada link deixando-os completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vfDBdy--1Fh"
   },
   "outputs": [],
   "source": [
    "for i in range(len(links)):\n",
    "  links[i] = host + links[i]\n",
    "\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crio a função que me ajudará a pegar o conteúdo de cada notícia em passos posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new(new_):\n",
    "    title = new_.find('h2',class_='post__title').text\n",
    "    time = new_.find('time').text\n",
    "    content = new_.find_all('p')\n",
    "\n",
    "    for i in range(len(content)-1,-1,-1):\n",
    "        if content[i].text == '' or content[i].find('span') != None or len(content[i].text) <= 20:\n",
    "            del content[i]\n",
    "        else:\n",
    "            content[i] = str(content[i].text)\n",
    "    \n",
    "    return {'title':title,'content':content,'time':time}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crio a função responsável por capturar cada uma das notícias via links passados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news(links):\n",
    "    news = []\n",
    "    for link in links:\n",
    "        r = BeautifulSoup(requests.get(link).content,features='html.parser')\n",
    "        new_ = r.find('div',class_='card__content')\n",
    "        post = get_new(new_)\n",
    "        news.append(post)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizo as funções acima definidas para fazer o scrapping do conteúdo de cada uma das notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news = get_all_news(links)\n",
    "print(all_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05SWvSnBCP3L"
   },
   "source": [
    "Crio a função que salva todas as notícias em arquivos .txt na minha máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1nQkz3mDh7X"
   },
   "outputs": [],
   "source": [
    "def save_news(all_news):\n",
    "    system(\"mkdir crawled_news\")\n",
    "    for n in all_news:\n",
    "       with  io.open('crawled_news/' + str(id(n)) + '.txt' , 'w',encoding='utf-8')  as file:\n",
    "        file.write('[TITLE] >> ' + n['title'] + '\\n')\n",
    "        file.write('[TIME] >> ' + n['time'] + '\\n')\n",
    "        file.write('[CONTENT]\\n')\n",
    "        for p in n['content']:\n",
    "            file.write('[PARAGRAPH]\\n')\n",
    "            file.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso a função definida acima para salvar as notícias crawleadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_news(all_news)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "crawler_flamengo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
